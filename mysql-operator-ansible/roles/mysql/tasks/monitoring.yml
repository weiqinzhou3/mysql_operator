---
# MySQL Monitoring and Health Check tasks

- name: Create MySQL monitoring ConfigMap
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: "{{ ansible_operator_meta.name }}-monitoring-scripts"
        namespace: "{{ ansible_operator_meta.namespace }}"
        labels:
          app: "{{ ansible_operator_meta.name }}"
          component: mysql-monitoring
      data:
        health-check.sh: |
          #!/bin/bash
          set -e
          
          echo "=== MySQL Health Check ==="
          echo "Timestamp: $(date)"
          echo "Host: ${MYSQL_HOST}"
          
          # Basic connectivity test
          echo "Testing MySQL connectivity..."
          mysql -h "${MYSQL_HOST}" -u root -p"${MYSQL_ROOT_PASSWORD}" -e "SELECT 1 as connectivity_test;" || exit 1
          
          # Check MySQL version
          echo "MySQL Version:"
          mysql -h "${MYSQL_HOST}" -u root -p"${MYSQL_ROOT_PASSWORD}" -e "SELECT VERSION();"
          
          # Check databases
          echo "Available Databases:"
          mysql -h "${MYSQL_HOST}" -u root -p"${MYSQL_ROOT_PASSWORD}" -e "SHOW DATABASES;"
          
          # Check process list
          echo "Process List:"
          mysql -h "${MYSQL_HOST}" -u root -p"${MYSQL_ROOT_PASSWORD}" -e "SHOW PROCESSLIST;"
          
          # Check status variables
          echo "Key Status Variables:"
          mysql -h "${MYSQL_HOST}" -u root -p"${MYSQL_ROOT_PASSWORD}" -e "
          SHOW STATUS LIKE 'Threads_connected';
          SHOW STATUS LIKE 'Threads_running';
          SHOW STATUS LIKE 'Uptime';
          SHOW STATUS LIKE 'Questions';
          "
          
          echo "Health check completed successfully"
        replication-check.sh: |
          #!/bin/bash
          set -e
          
          echo "=== MySQL Replication Health Check ==="
          echo "Timestamp: $(date)"
          
          if [ "${COMPONENT}" = "mysql-master" ]; then
              echo "Checking MASTER status..."
              mysql -h "${MYSQL_HOST}" -u root -p"${MYSQL_ROOT_PASSWORD}" -e "SHOW MASTER STATUS\G"
              
              echo "Connected slaves:"
              mysql -h "${MYSQL_HOST}" -u root -p"${MYSQL_ROOT_PASSWORD}" -e "SHOW SLAVE HOSTS;"
              
          elif [ "${COMPONENT}" = "mysql-slave" ]; then
              echo "Checking SLAVE status..."
              SLAVE_STATUS=$(mysql -h "${MYSQL_HOST}" -u root -p"${MYSQL_ROOT_PASSWORD}" -e "SHOW SLAVE STATUS\G")
              echo "${SLAVE_STATUS}"
              
              # Check critical replication parameters
              IO_RUNNING=$(echo "${SLAVE_STATUS}" | grep "Slave_IO_Running:" | awk '{print $2}')
              SQL_RUNNING=$(echo "${SLAVE_STATUS}" | grep "Slave_SQL_Running:" | awk '{print $2}')
              
              echo "Slave_IO_Running: ${IO_RUNNING}"
              echo "Slave_SQL_Running: ${SQL_RUNNING}"
              
              if [ "${IO_RUNNING}" != "Yes" ] || [ "${SQL_RUNNING}" != "Yes" ]; then
                  echo "WARNING: Slave replication is not running properly!"
                  exit 1
              fi
              
              # Check replication lag
              SECONDS_BEHIND=$(echo "${SLAVE_STATUS}" | grep "Seconds_Behind_Master:" | awk '{print $2}')
              echo "Seconds_Behind_Master: ${SECONDS_BEHIND}"
              
              if [ "${SECONDS_BEHIND}" != "NULL" ] && [ "${SECONDS_BEHIND}" -gt 300 ]; then
                  echo "WARNING: Replication lag is high (${SECONDS_BEHIND} seconds)"
              fi
          fi
          
          echo "Replication check completed"
        performance-check.sh: |
          #!/bin/bash
          set -e
          
          echo "=== MySQL Performance Check ==="
          echo "Timestamp: $(date)"
          
          # Key performance metrics
          mysql -h "${MYSQL_HOST}" -u root -p"${MYSQL_ROOT_PASSWORD}" -e "
          SELECT 
              'Connection Usage' as metric,
              VARIABLE_VALUE as current_connections,
              (SELECT VARIABLE_VALUE FROM performance_schema.global_variables WHERE VARIABLE_NAME = 'max_connections') as max_connections,
              ROUND((VARIABLE_VALUE / (SELECT VARIABLE_VALUE FROM performance_schema.global_variables WHERE VARIABLE_NAME = 'max_connections')) * 100, 2) as usage_percent
          FROM performance_schema.global_status 
          WHERE VARIABLE_NAME = 'Threads_connected';
          
          SELECT 
              'InnoDB Buffer Pool' as metric,
              ROUND(SUM(data_length + index_length) / 1024 / 1024, 2) as total_size_mb,
              (SELECT VARIABLE_VALUE / 1024 / 1024 FROM performance_schema.global_variables WHERE VARIABLE_NAME = 'innodb_buffer_pool_size') as buffer_pool_mb
          FROM information_schema.tables 
          WHERE engine = 'InnoDB';
          
          SELECT 
              'Slow Query Log' as metric,
              VARIABLE_VALUE as slow_queries
          FROM performance_schema.global_status 
          WHERE VARIABLE_NAME = 'Slow_queries';
          "
          
          echo "Performance check completed"

- name: Create MySQL monitoring Service
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: v1
      kind: Service
      metadata:
        name: "{{ ansible_operator_meta.name }}-monitoring"
        namespace: "{{ ansible_operator_meta.namespace }}"
        labels:
          app: "{{ ansible_operator_meta.name }}"
          component: mysql-monitoring
        annotations:
          prometheus.io/scrape: "true"
          prometheus.io/port: "9104"
          prometheus.io/path: "/metrics"
      spec:
        type: ClusterIP
        ports:
        - port: 9104
          targetPort: 9104
          protocol: TCP
          name: metrics
        selector:
          app: "{{ ansible_operator_meta.name }}"
          component: mysql-monitoring

- name: Create MySQL exporter Deployment for Prometheus monitoring
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: "{{ ansible_operator_meta.name }}-exporter"
        namespace: "{{ ansible_operator_meta.namespace }}"
        labels:
          app: "{{ ansible_operator_meta.name }}"
          component: mysql-monitoring
      spec:
        replicas: 1
        selector:
          matchLabels:
            app: "{{ ansible_operator_meta.name }}"
            component: mysql-monitoring
        template:
          metadata:
            labels:
              app: "{{ ansible_operator_meta.name }}"
              component: mysql-monitoring
          spec:
            containers:
            - name: mysql-exporter
              image: prom/mysqld-exporter:v0.14.0
              ports:
              - containerPort: 9104
                name: metrics
              env:
              - name: DATA_SOURCE_NAME
                value: "root:$(MYSQL_ROOT_PASSWORD)@({{ ansible_operator_meta.name }}-master:3306)/"
              - name: MYSQL_ROOT_PASSWORD
                valueFrom:
                  secretKeyRef:
                    name: "{{ ansible_operator_meta.name }}-secret"
                    key: mysql-root-password
              livenessProbe:
                httpGet:
                  path: /metrics
                  port: 9104
                initialDelaySeconds: 30
                periodSeconds: 30
              readinessProbe:
                httpGet:
                  path: /metrics
                  port: 9104
                initialDelaySeconds: 5
                periodSeconds: 5
              resources:
                requests:
                  memory: "64Mi"
                  cpu: "50m"
                limits:
                  memory: "128Mi"
                  cpu: "100m"

- name: Create health check CronJob
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: batch/v1
      kind: CronJob
      metadata:
        name: "{{ ansible_operator_meta.name }}-health-check"
        namespace: "{{ ansible_operator_meta.namespace }}"
        labels:
          app: "{{ ansible_operator_meta.name }}"
          component: mysql-health-check
      spec:
        schedule: "*/5 * * * *"  # Every 5 minutes
        concurrencyPolicy: Forbid
        successfulJobsHistoryLimit: 3
        failedJobsHistoryLimit: 3
        jobTemplate:
          spec:
            template:
              metadata:
                labels:
                  app: "{{ ansible_operator_meta.name }}"
                  component: mysql-health-check-job
              spec:
                restartPolicy: OnFailure
                containers:
                - name: health-checker
                  image: mysql:8.0
                  command:
                  - /bin/bash
                  - /scripts/health-check.sh
                  env:
                  - name: MYSQL_HOST
                    value: "{{ ansible_operator_meta.name }}-master"
                  - name: MYSQL_ROOT_PASSWORD
                    valueFrom:
                      secretKeyRef:
                        name: "{{ ansible_operator_meta.name }}-secret"
                        key: mysql-root-password
                  volumeMounts:
                  - name: monitoring-scripts
                    mountPath: /scripts
                volumes:
                - name: monitoring-scripts
                  configMap:
                    name: "{{ ansible_operator_meta.name }}-monitoring-scripts"
                    defaultMode: 0755

- name: Create replication health check CronJob (for master-slave mode)
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: batch/v1
      kind: CronJob
      metadata:
        name: "{{ ansible_operator_meta.name }}-replication-check"
        namespace: "{{ ansible_operator_meta.namespace }}"
        labels:
          app: "{{ ansible_operator_meta.name }}"
          component: mysql-replication-check
      spec:
        schedule: "*/2 * * * *"  # Every 2 minutes
        concurrencyPolicy: Forbid
        successfulJobsHistoryLimit: 2
        failedJobsHistoryLimit: 2
        jobTemplate:
          spec:
            template:
              metadata:
                labels:
                  app: "{{ ansible_operator_meta.name }}"
                  component: mysql-replication-check-job
              spec:
                restartPolicy: OnFailure
                containers:
                - name: master-check
                  image: mysql:8.0
                  command:
                  - /bin/bash
                  - /scripts/replication-check.sh
                  env:
                  - name: MYSQL_HOST
                    value: "{{ ansible_operator_meta.name }}-master"
                  - name: COMPONENT
                    value: "mysql-master"
                  - name: MYSQL_ROOT_PASSWORD
                    valueFrom:
                      secretKeyRef:
                        name: "{{ ansible_operator_meta.name }}-secret"
                        key: mysql-root-password
                  volumeMounts:
                  - name: monitoring-scripts
                    mountPath: /scripts
                - name: slave-check
                  image: mysql:8.0
                  command:
                  - /bin/bash
                  - /scripts/replication-check.sh
                  env:
                  - name: MYSQL_HOST
                    value: "{{ ansible_operator_meta.name }}-slave"
                  - name: COMPONENT
                    value: "mysql-slave"
                  - name: MYSQL_ROOT_PASSWORD
                    valueFrom:
                      secretKeyRef:
                        name: "{{ ansible_operator_meta.name }}-secret"
                        key: mysql-root-password
                  volumeMounts:
                  - name: monitoring-scripts
                    mountPath: /scripts
                volumes:
                - name: monitoring-scripts
                  configMap:
                    name: "{{ ansible_operator_meta.name }}-monitoring-scripts"
                    defaultMode: 0755
  when: deployment_mode == "master-slave"